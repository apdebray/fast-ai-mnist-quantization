{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch                     # for all things PyTorch\n",
        "import torch.nn as nn            # for torch.nn.Module, the parent object for PyTorch models\n",
        "import torch.nn.functional as F  # for the activation function"
      ],
      "metadata": {
        "id": "mg4-FPkptpN4"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "A2yYTfgFt0qu"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = LeNet()\n",
        "print(net)                         # what does the object tell us about itself?\n",
        "\n",
        "input = torch.rand(1, 1, 32, 32)   # stand-in for a 32x32 black & white image\n",
        "print('\\nImage batch shape:')\n",
        "print(input.shape)\n",
        "\n",
        "output = net(input)                # we don't call forward() directly\n",
        "print('\\nRaw output:')\n",
        "print(output)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "id": "ozoVJjlruAdM",
        "outputId": "7f824ab5-49fd-4552-c116-db34557af21a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeNet(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n",
            "\n",
            "Image batch shape:\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "Raw output:\n",
            "tensor([[-0.0164,  0.1396,  0.0208,  0.0906, -0.0294,  0.0429,  0.0394,  0.0114,\n",
            "         -0.0208, -0.0270]], grad_fn=<AddmmBackward0>)\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "id": "J6MJTlJ3gDjV"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the MNIST training and test sets and transform images to PyTorch tensors (numerical arrays). Each image is 28×28 grayscale, and each label is one of 10 digits. After downloading, the code below creates data loaders for convenient batching:"
      ],
      "metadata": {
        "id": "yyYbAp4BgfD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64)"
      ],
      "metadata": {
        "id": "7lRf6hdwgaDe"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prepares to feed the data in batches of 64 images at a time (common for training)\n",
        "docs.pytorch.org\n",
        "docs.pytorch.org\n",
        "."
      ],
      "metadata": {
        "id": "2KYT2G42grc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.fc_stack = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 7 * 7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.4),  # Dropout added here\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.fc_stack(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model\n",
        "model = ConvNet()"
      ],
      "metadata": {
        "id": "7HWGmrNAguQn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model definition corresponds to the diagram above: flatten input to 784, then two linear layers with ReLU, then a final linear layer to get 10 outputs.\n",
        "\n",
        "Using PyTorch’s torch.nn module, define a simple feed-forward neural network. For example, you can create a class NeuralNetwork(nn.Module) with an __init__ that sets up layers, and a forward method that defines how data flows. A basic architecture for MNIST could be:\n",
        "\n",
        "Input layer: 784 inputs (since 28*28 pixels are flattened into a vector).\n",
        "\n",
        "Hidden layer 1: 512 neurons + ReLU activation.\n",
        "\n",
        "Hidden layer 2: 512 neurons + ReLU activation.\n",
        "\n",
        "Output layer: 10 neurons (one for each digit class).\n"
      ],
      "metadata": {
        "id": "MpMoFEY2hT32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)"
      ],
      "metadata": {
        "id": "pYDwyESxhYI_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, I set up a loss function and optimizer for training. For multi-class classification, I use cross-entropy loss (nn.CrossEntropyLoss), and a simple optimizer like Stochastic Gradient Descent (torch.optim.SGD). Here we use a learning rate of 0.01 (1e-2) – this might be adjusted if needed. Now write the training loop. Loop for a certain number of epochs (passes through the dataset, say 5 epochs to start). In each epoch, iterate over train_loader batches:"
      ],
      "metadata": {
        "id": "cuwP_ThFhiVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1} complete | Avg Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m52k8-8Jhol0",
        "outputId": "8038d70f-84e3-4080-e51c-a7ed92fe9260"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0, Loss: 2.3045\n",
            "Epoch 1, Batch 100, Loss: 0.2733\n",
            "Epoch 1, Batch 200, Loss: 0.2026\n",
            "Epoch 1, Batch 300, Loss: 0.1019\n",
            "Epoch 1, Batch 400, Loss: 0.2037\n",
            "Epoch 1, Batch 500, Loss: 0.2379\n",
            "Epoch 1, Batch 600, Loss: 0.0838\n",
            "Epoch 1, Batch 700, Loss: 0.0325\n",
            "Epoch 1, Batch 800, Loss: 0.0676\n",
            "Epoch 1, Batch 900, Loss: 0.0180\n",
            "Epoch 1 complete | Avg Loss: 0.1936\n",
            "Epoch 2, Batch 0, Loss: 0.0672\n",
            "Epoch 2, Batch 100, Loss: 0.1193\n",
            "Epoch 2, Batch 200, Loss: 0.0562\n",
            "Epoch 2, Batch 300, Loss: 0.0595\n",
            "Epoch 2, Batch 400, Loss: 0.0080\n",
            "Epoch 2, Batch 500, Loss: 0.0963\n",
            "Epoch 2, Batch 600, Loss: 0.0725\n",
            "Epoch 2, Batch 700, Loss: 0.0234\n",
            "Epoch 2, Batch 800, Loss: 0.0228\n",
            "Epoch 2, Batch 900, Loss: 0.0219\n",
            "Epoch 2 complete | Avg Loss: 0.0683\n",
            "Epoch 3, Batch 0, Loss: 0.0080\n",
            "Epoch 3, Batch 100, Loss: 0.0490\n",
            "Epoch 3, Batch 200, Loss: 0.0401\n",
            "Epoch 3, Batch 300, Loss: 0.0671\n",
            "Epoch 3, Batch 400, Loss: 0.0054\n",
            "Epoch 3, Batch 500, Loss: 0.0472\n",
            "Epoch 3, Batch 600, Loss: 0.0052\n",
            "Epoch 3, Batch 700, Loss: 0.0541\n",
            "Epoch 3, Batch 800, Loss: 0.0696\n",
            "Epoch 3, Batch 900, Loss: 0.0267\n",
            "Epoch 3 complete | Avg Loss: 0.0505\n",
            "Epoch 4, Batch 0, Loss: 0.0419\n",
            "Epoch 4, Batch 100, Loss: 0.0051\n",
            "Epoch 4, Batch 200, Loss: 0.0143\n",
            "Epoch 4, Batch 300, Loss: 0.0130\n",
            "Epoch 4, Batch 400, Loss: 0.0506\n",
            "Epoch 4, Batch 500, Loss: 0.0295\n",
            "Epoch 4, Batch 600, Loss: 0.0369\n",
            "Epoch 4, Batch 700, Loss: 0.1187\n",
            "Epoch 4, Batch 800, Loss: 0.0095\n",
            "Epoch 4, Batch 900, Loss: 0.0397\n",
            "Epoch 4 complete | Avg Loss: 0.0406\n",
            "Epoch 5, Batch 0, Loss: 0.0241\n",
            "Epoch 5, Batch 100, Loss: 0.0182\n",
            "Epoch 5, Batch 200, Loss: 0.0159\n",
            "Epoch 5, Batch 300, Loss: 0.0024\n",
            "Epoch 5, Batch 400, Loss: 0.0013\n",
            "Epoch 5, Batch 500, Loss: 0.0097\n",
            "Epoch 5, Batch 600, Loss: 0.0097\n",
            "Epoch 5, Batch 700, Loss: 0.0034\n",
            "Epoch 5, Batch 800, Loss: 0.0350\n",
            "Epoch 5, Batch 900, Loss: 0.0181\n",
            "Epoch 5 complete | Avg Loss: 0.0332\n",
            "Epoch 6, Batch 0, Loss: 0.0050\n",
            "Epoch 6, Batch 100, Loss: 0.0216\n",
            "Epoch 6, Batch 200, Loss: 0.0028\n",
            "Epoch 6, Batch 300, Loss: 0.0285\n",
            "Epoch 6, Batch 400, Loss: 0.0077\n",
            "Epoch 6, Batch 500, Loss: 0.0404\n",
            "Epoch 6, Batch 600, Loss: 0.0060\n",
            "Epoch 6, Batch 700, Loss: 0.0280\n",
            "Epoch 6, Batch 800, Loss: 0.0828\n",
            "Epoch 6, Batch 900, Loss: 0.0146\n",
            "Epoch 6 complete | Avg Loss: 0.0283\n",
            "Epoch 7, Batch 0, Loss: 0.0036\n",
            "Epoch 7, Batch 100, Loss: 0.0166\n",
            "Epoch 7, Batch 200, Loss: 0.0025\n",
            "Epoch 7, Batch 300, Loss: 0.0134\n",
            "Epoch 7, Batch 400, Loss: 0.0004\n",
            "Epoch 7, Batch 500, Loss: 0.0372\n",
            "Epoch 7, Batch 600, Loss: 0.0002\n",
            "Epoch 7, Batch 700, Loss: 0.0474\n",
            "Epoch 7, Batch 800, Loss: 0.0854\n",
            "Epoch 7, Batch 900, Loss: 0.0077\n",
            "Epoch 7 complete | Avg Loss: 0.0241\n",
            "Epoch 8, Batch 0, Loss: 0.0155\n",
            "Epoch 8, Batch 100, Loss: 0.0172\n",
            "Epoch 8, Batch 200, Loss: 0.0030\n",
            "Epoch 8, Batch 300, Loss: 0.0140\n",
            "Epoch 8, Batch 400, Loss: 0.0105\n",
            "Epoch 8, Batch 500, Loss: 0.0146\n",
            "Epoch 8, Batch 600, Loss: 0.1308\n",
            "Epoch 8, Batch 700, Loss: 0.0099\n",
            "Epoch 8, Batch 800, Loss: 0.0077\n",
            "Epoch 8, Batch 900, Loss: 0.0020\n",
            "Epoch 8 complete | Avg Loss: 0.0207\n",
            "Epoch 9, Batch 0, Loss: 0.0309\n",
            "Epoch 9, Batch 100, Loss: 0.0153\n",
            "Epoch 9, Batch 200, Loss: 0.0002\n",
            "Epoch 9, Batch 300, Loss: 0.0009\n",
            "Epoch 9, Batch 400, Loss: 0.0057\n",
            "Epoch 9, Batch 500, Loss: 0.0351\n",
            "Epoch 9, Batch 600, Loss: 0.0076\n",
            "Epoch 9, Batch 700, Loss: 0.0549\n",
            "Epoch 9, Batch 800, Loss: 0.0206\n",
            "Epoch 9, Batch 900, Loss: 0.0016\n",
            "Epoch 9 complete | Avg Loss: 0.0194\n",
            "Epoch 10, Batch 0, Loss: 0.0019\n",
            "Epoch 10, Batch 100, Loss: 0.0405\n",
            "Epoch 10, Batch 200, Loss: 0.0021\n",
            "Epoch 10, Batch 300, Loss: 0.0376\n",
            "Epoch 10, Batch 400, Loss: 0.0167\n",
            "Epoch 10, Batch 500, Loss: 0.0351\n",
            "Epoch 10, Batch 600, Loss: 0.0322\n",
            "Epoch 10, Batch 700, Loss: 0.0062\n",
            "Epoch 10, Batch 800, Loss: 0.0030\n",
            "Epoch 10, Batch 900, Loss: 0.0012\n",
            "Epoch 10 complete | Avg Loss: 0.0185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This loop does: for each batch, get predictions, compute the loss against true labels, then do backpropagation (loss.backward()) and update weights (optimizer.step()), clearing gradients in between\n",
        "docs.pytorch.org\n",
        "docs.pytorch.org\n",
        ". The model’s parameters get adjusted in each step to reduce the loss. By the end of each epoch, the network has seen all training examples once. Print a message or loss value occasionally to track progress."
      ],
      "metadata": {
        "id": "2p69i4Ruh3ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()  # set to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # no grad needed for eval\n",
        "    for X, y in test_loader:\n",
        "        X, y = X.to(\"cuda\"), y.to(\"cuda\")\n",
        "        pred = model(X)\n",
        "        # pick class with highest predicted score for each sample\n",
        "        predicted_labels = pred.argmax(dim=1)\n",
        "        correct += (predicted_labels == y).sum().item()\n",
        "        total += y.size(0)\n",
        "print(f\"Test Accuracy: {100 * correct/total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9hNYavBi3FK",
        "outputId": "8c1da074-8901-4363-ec2e-19f6f4717562"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 99.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is a visualization of a random image from the MINST dataset and then the model I created being run on the image. The predicted output from the image is listed below the code."
      ],
      "metadata": {
        "id": "SvSOA9EYkojn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "images, labels = next(iter(test_loader))\n",
        "images = images.to(device)\n",
        "outputs = model(images)\n",
        "preds = outputs.argmax(dim=1)\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "    plt.title(f\"P:{preds[i].item()} / T:{labels[i].item()}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "OkHuI9iqkfZ7",
        "outputId": "0e691d9c-09f1-4c2c-83c0-c43d74379afd"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save\n",
        "torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
        "\n",
        "# Load later\n",
        "model.load_state_dict(torch.load(\"mnist_cnn.pt\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFqKGkNkq-OI",
        "outputId": "735ffae4-1f7a-482d-a79f-364205ae4d44"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvNet(\n",
              "  (conv_stack): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): ReLU()\n",
              "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc_stack): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=3136, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.4, inplace=False)\n",
              "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To improve model performance on the MNIST digit classification task, several key techniques were implemented. The input data was normalized using the dataset’s mean and standard deviation to stabilize and accelerate training. A convolutional neural network (CNN) architecture was used in place of a basic feedforward network, allowing the model to better capture spatial patterns in image data. Dropout regularization was added to the fully connected layers to reduce overfitting. The optimizer was upgraded from stochastic gradient descent (SGD) to Adam, which adapts learning rates and generally leads to faster convergence. The model was trained over 10 epochs with loss tracking per batch and epoch to monitor performance. Together, these improvements raised the model’s accuracy to 99.23%, demonstrating high generalization and robustness."
      ],
      "metadata": {
        "id": "7qnKObRRr4vo"
      }
    }
  ]
}