{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "FIRST Rebuilding Model, explicitly explaining Linear layers to better transfer over to be compatible for quantization"
      ],
      "metadata": {
        "id": "FTd755Sz7c4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# âœ… 1. Define the quantization-compatible model\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv_stack = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_stack(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# âœ… 2. Load MNIST data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_data = datasets.MNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "# âœ… 3. Training setup\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = ConvNet().to(device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# âœ… 4. Train the model\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (X, y) in enumerate(train_loader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print(f\"Epoch {epoch+1}, Batch {batch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"âœ… Epoch {epoch+1} complete | Avg Loss: {avg_loss:.4f}\")\n",
        "\n",
        "# âœ… 5. Evaluate the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        pred = model(X)\n",
        "        predicted = pred.argmax(dim=1)\n",
        "        correct += (predicted == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"ðŸŽ¯ Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "# âœ… 6. Visualize predictions (first 10)\n",
        "images, labels = next(iter(test_loader))\n",
        "images = images.to(device)\n",
        "outputs = model(images)\n",
        "preds = outputs.argmax(dim=1)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1)\n",
        "    plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "    plt.title(f\"P:{preds[i].item()} / T:{labels[i].item()}\")\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "# âœ… 7. Save the trained model (for quantization)\n",
        "model.to(\"cpu\")\n",
        "torch.save(model.state_dict(), \"mnist_cnn_clean.pt\")\n",
        "print(\"âœ… Model saved to mnist_cnn_clean.pt (quantization-ready)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "maNbuWrK1vqo",
        "outputId": "8612b139-5f9e-4030-da6a-d599a9c32760"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Batch 0, Loss: 2.2873\n",
            "Epoch 1, Batch 100, Loss: 0.2432\n",
            "Epoch 1, Batch 200, Loss: 0.1135\n",
            "Epoch 1, Batch 300, Loss: 0.1010\n",
            "Epoch 1, Batch 400, Loss: 0.0903\n",
            "Epoch 1, Batch 500, Loss: 0.1016\n",
            "Epoch 1, Batch 600, Loss: 0.2505\n",
            "Epoch 1, Batch 700, Loss: 0.0401\n",
            "Epoch 1, Batch 800, Loss: 0.0194\n",
            "Epoch 1, Batch 900, Loss: 0.0590\n",
            "âœ… Epoch 1 complete | Avg Loss: 0.1826\n",
            "Epoch 2, Batch 0, Loss: 0.1533\n",
            "Epoch 2, Batch 100, Loss: 0.1002\n",
            "Epoch 2, Batch 200, Loss: 0.0317\n",
            "Epoch 2, Batch 300, Loss: 0.1792\n",
            "Epoch 2, Batch 400, Loss: 0.0531\n",
            "Epoch 2, Batch 500, Loss: 0.0769\n",
            "Epoch 2, Batch 600, Loss: 0.0948\n",
            "Epoch 2, Batch 700, Loss: 0.0260\n",
            "Epoch 2, Batch 800, Loss: 0.0832\n",
            "Epoch 2, Batch 900, Loss: 0.0599\n",
            "âœ… Epoch 2 complete | Avg Loss: 0.0654\n",
            "Epoch 3, Batch 0, Loss: 0.0205\n",
            "Epoch 3, Batch 100, Loss: 0.0125\n",
            "Epoch 3, Batch 200, Loss: 0.0409\n",
            "Epoch 3, Batch 300, Loss: 0.0182\n",
            "Epoch 3, Batch 400, Loss: 0.0175\n",
            "Epoch 3, Batch 500, Loss: 0.0103\n",
            "Epoch 3, Batch 600, Loss: 0.0337\n",
            "Epoch 3, Batch 700, Loss: 0.1118\n",
            "Epoch 3, Batch 800, Loss: 0.0032\n",
            "Epoch 3, Batch 900, Loss: 0.1033\n",
            "âœ… Epoch 3 complete | Avg Loss: 0.0474\n",
            "Epoch 4, Batch 0, Loss: 0.0213\n",
            "Epoch 4, Batch 100, Loss: 0.0337\n",
            "Epoch 4, Batch 200, Loss: 0.0048\n",
            "Epoch 4, Batch 300, Loss: 0.1177\n",
            "Epoch 4, Batch 400, Loss: 0.0160\n",
            "Epoch 4, Batch 500, Loss: 0.0026\n",
            "Epoch 4, Batch 600, Loss: 0.0131\n",
            "Epoch 4, Batch 700, Loss: 0.0199\n",
            "Epoch 4, Batch 800, Loss: 0.0057\n",
            "Epoch 4, Batch 900, Loss: 0.0118\n",
            "âœ… Epoch 4 complete | Avg Loss: 0.0371\n",
            "Epoch 5, Batch 0, Loss: 0.0078\n",
            "Epoch 5, Batch 100, Loss: 0.1016\n",
            "Epoch 5, Batch 200, Loss: 0.0260\n",
            "Epoch 5, Batch 300, Loss: 0.0029\n",
            "Epoch 5, Batch 400, Loss: 0.0401\n",
            "Epoch 5, Batch 500, Loss: 0.0288\n",
            "Epoch 5, Batch 600, Loss: 0.0124\n",
            "Epoch 5, Batch 700, Loss: 0.0112\n",
            "Epoch 5, Batch 800, Loss: 0.1165\n",
            "Epoch 5, Batch 900, Loss: 0.0407\n",
            "âœ… Epoch 5 complete | Avg Loss: 0.0305\n",
            "Epoch 6, Batch 0, Loss: 0.0153\n",
            "Epoch 6, Batch 100, Loss: 0.0114\n",
            "Epoch 6, Batch 200, Loss: 0.0296\n",
            "Epoch 6, Batch 300, Loss: 0.0652\n",
            "Epoch 6, Batch 400, Loss: 0.1099\n",
            "Epoch 6, Batch 500, Loss: 0.0013\n",
            "Epoch 6, Batch 600, Loss: 0.0346\n",
            "Epoch 6, Batch 700, Loss: 0.0306\n",
            "Epoch 6, Batch 800, Loss: 0.0319\n",
            "Epoch 6, Batch 900, Loss: 0.0406\n",
            "âœ… Epoch 6 complete | Avg Loss: 0.0262\n",
            "Epoch 7, Batch 0, Loss: 0.0313\n",
            "Epoch 7, Batch 100, Loss: 0.0074\n",
            "Epoch 7, Batch 200, Loss: 0.0070\n",
            "Epoch 7, Batch 300, Loss: 0.0104\n",
            "Epoch 7, Batch 400, Loss: 0.0003\n",
            "Epoch 7, Batch 500, Loss: 0.0394\n",
            "Epoch 7, Batch 600, Loss: 0.1031\n",
            "Epoch 7, Batch 700, Loss: 0.0264\n",
            "Epoch 7, Batch 800, Loss: 0.0040\n",
            "Epoch 7, Batch 900, Loss: 0.0036\n",
            "âœ… Epoch 7 complete | Avg Loss: 0.0229\n",
            "Epoch 8, Batch 0, Loss: 0.0407\n",
            "Epoch 8, Batch 100, Loss: 0.0013\n",
            "Epoch 8, Batch 200, Loss: 0.0038\n",
            "Epoch 8, Batch 300, Loss: 0.0016\n",
            "Epoch 8, Batch 400, Loss: 0.0053\n",
            "Epoch 8, Batch 500, Loss: 0.0044\n",
            "Epoch 8, Batch 600, Loss: 0.0005\n",
            "Epoch 8, Batch 700, Loss: 0.0073\n",
            "Epoch 8, Batch 800, Loss: 0.0104\n",
            "Epoch 8, Batch 900, Loss: 0.0262\n",
            "âœ… Epoch 8 complete | Avg Loss: 0.0197\n",
            "Epoch 9, Batch 0, Loss: 0.0281\n",
            "Epoch 9, Batch 100, Loss: 0.0066\n",
            "Epoch 9, Batch 200, Loss: 0.0034\n",
            "Epoch 9, Batch 300, Loss: 0.0002\n",
            "Epoch 9, Batch 400, Loss: 0.0055\n",
            "Epoch 9, Batch 500, Loss: 0.0017\n",
            "Epoch 9, Batch 600, Loss: 0.0050\n",
            "Epoch 9, Batch 700, Loss: 0.0450\n",
            "Epoch 9, Batch 800, Loss: 0.0220\n",
            "Epoch 9, Batch 900, Loss: 0.0192\n",
            "âœ… Epoch 9 complete | Avg Loss: 0.0175\n",
            "Epoch 10, Batch 0, Loss: 0.0024\n",
            "Epoch 10, Batch 100, Loss: 0.0046\n",
            "Epoch 10, Batch 200, Loss: 0.0077\n",
            "Epoch 10, Batch 300, Loss: 0.0029\n",
            "Epoch 10, Batch 400, Loss: 0.0007\n",
            "Epoch 10, Batch 500, Loss: 0.0099\n",
            "Epoch 10, Batch 600, Loss: 0.0030\n",
            "Epoch 10, Batch 700, Loss: 0.0602\n",
            "Epoch 10, Batch 800, Loss: 0.0005\n",
            "Epoch 10, Batch 900, Loss: 0.0079\n",
            "âœ… Epoch 10 complete | Avg Loss: 0.0142\n",
            "ðŸŽ¯ Test Accuracy: 99.30%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Model saved to mnist_cnn_clean.pt (quantization-ready)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUANTIZATION STEP"
      ],
      "metadata": {
        "id": "WCKtFiNb8GM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Reuse the same ConvNet class\n",
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load(\"mnist_cnn_clean.pt\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "# Apply dynamic quantization (targeting Linear layers only)\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {nn.Linear}, dtype=torch.qint8\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I4v5Ad75T3r",
        "outputId": "4b60f621-536b-4f06-cd50-8f0cceef6133"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1364863828.py:10: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  quantized_model = torch.quantization.quantize_dynamic(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "COMPARING MODEL PERFORMANCE"
      ],
      "metadata": {
        "id": "XonjrfNB8I5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "        outputs = quantized_model(X)\n",
        "        predicted = outputs.argmax(dim=1)\n",
        "        correct += (predicted == y).sum().item()\n",
        "        total += y.size(0)\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"âœ… Quantized Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwcsqze85Vd-",
        "outputId": "2a426f60-f6d5-4c52-c557-ccd733f7dbfd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Quantized Model Accuracy: 99.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIZE REDUCTION COMPARISON"
      ],
      "metadata": {
        "id": "h9izGc7L8L0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "torch.save(model.state_dict(), \"mnist_original.pt\")\n",
        "torch.save(quantized_model.state_dict(), \"mnist_quantized.pt\")\n",
        "\n",
        "original_size = os.path.getsize(\"mnist_original.pt\") / 1024\n",
        "quantized_size = os.path.getsize(\"mnist_quantized.pt\") / 1024\n",
        "\n",
        "print(f\"ðŸ“¦ Original: {original_size:.2f} KB\")\n",
        "print(f\"ðŸ“¦ Quantized: {quantized_size:.2f} KB\")\n",
        "print(f\"ðŸ’¡ Reduction: {100 * (original_size - quantized_size) / original_size:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzllW8zR5beS",
        "outputId": "c382f587-c11f-4ed6-dff4-3914a4d4703f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Original: 1650.80 KB\n",
            "ðŸ“¦ Quantized: 472.45 KB\n",
            "ðŸ’¡ Reduction: 71.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXPORTING TO ONNX"
      ],
      "metadata": {
        "id": "hGerFq6g8OIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "dummy_input = torch.randn(1, 1, 28, 28)\n"
      ],
      "metadata": {
        "id": "My87wjT45tth"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet()\n",
        "model.load_state_dict(torch.load(\"mnist_cnn_clean.pt\", map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 1, 28, 28)\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,                      # full-precision model\n",
        "    dummy_input,\n",
        "    \"mnist.onnx\",\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
        "    opset_version=12\n",
        ")\n",
        "\n",
        "print(\"âœ… Full-precision model exported to mnist.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgvMGxcE5w63",
        "outputId": "0efa753a-4e85-496f-dd3a-90f5d70da5ca"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Full-precision model exported to mnist.onnx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-436393442.py:7: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.\n",
            "  torch.onnx.export(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "quantize_dynamic(\n",
        "    model_input=\"mnist.onnx\",\n",
        "    model_output=\"mnist_quantized_linear.onnx\",\n",
        "    weight_type=QuantType.QInt8,\n",
        "    op_types_to_quantize=[\"MatMul\", \"Add\"]  # only quantize linear ops\n",
        ")\n",
        "\n",
        "print(\"âœ… Re-quantized with linear ops only â†’ mnist_quantized_linear.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x08xnWj76g4K",
        "outputId": "894107ee-571a-46c9-defb-bc87fcb2cfce"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Re-quantized with linear ops only â†’ mnist_quantized_linear.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "original_size = os.path.getsize(\"mnist.onnx\") / 1024\n",
        "quantized_size = os.path.getsize(\"mnist_quantized.onnx\") / 1024\n",
        "\n",
        "print(f\"ðŸ“¦ Original ONNX model: {original_size:.2f} KB\")\n",
        "print(f\"ðŸ“¦ Quantized ONNX model: {quantized_size:.2f} KB\")\n",
        "print(f\"ðŸ’¡ Size reduction: {100 * (original_size - quantized_size) / original_size:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDYKQfkf6jvk",
        "outputId": "1dac8d8c-36a6-4908-b2d7-4eee612f01b3"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ Original ONNX model: 1648.93 KB\n",
            "ðŸ“¦ Quantized ONNX model: 419.49 KB\n",
            "ðŸ’¡ Size reduction: 74.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Load new quantized model\n",
        "session = ort.InferenceSession(\"mnist_quantized_linear.onnx\")\n",
        "\n",
        "input_name = session.get_inputs()[0].name\n",
        "X_sample, y_sample = next(iter(test_loader))\n",
        "sample_input = X_sample[0:1].numpy()\n",
        "\n",
        "output = session.run(None, {input_name: sample_input})\n",
        "predicted = np.argmax(output[0])\n",
        "\n",
        "print(f\"ðŸ§  ONNX Prediction: {predicted}\")\n",
        "print(f\"ðŸŽ¯ Ground Truth: {y_sample[0].item()}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Afph6YCu6nTF",
        "outputId": "321a336b-203a-41a3-b6e8-8d7a02ee4e34"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  ONNX Prediction: 7\n",
            "ðŸŽ¯ Ground Truth: 7\n"
          ]
        }
      ]
    }
  ]
}