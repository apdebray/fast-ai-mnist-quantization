# üß† MNIST CNN Classifier & Deployment Pipeline (PyTorch ‚Üí ONNX)

This project documents my journey building a high-accuracy convolutional neural network (CNN) using PyTorch, then optimizing it through **quantization** and **ONNX export** ‚Äî skills directly aligned with the USAF/MIT **Phantom AI ‚Äì Fast AI track**.

---

## ‚úÖ What I Built

- A clean CNN trained on the MNIST dataset, achieving **99.3% test accuracy**
- Model optimization using **PyTorch dynamic quantization** (‚Üì71% model size)
- Deployment-ready model via **ONNX export + post-export quantization**
- Inference validation using **ONNX Runtime**

---

## üß† Skills & Concepts Practiced

- CNN design for image classification
- Training pipelines with PyTorch (data loaders, GPU acceleration)
- Performance tuning (Adam optimizer, dropout, normalization)
- Model compression with `torch.quantization`
- ONNX model export and quantization via `onnxruntime`
- Inference execution outside PyTorch

---

## üìÅ File Overview

| File | Description |
|------|-------------|
| `MNIST_CNN_Training.ipynb` | CNN architecture, training loop, and evaluation (Day 1) |
| `Model_Quantization_ONNX.ipynb` | PyTorch ‚Üí ONNX quantization + runtime validation (Day 2) |
| `requirements.txt` | All necessary libraries |

---

## üî¢ Results

| Model            | Accuracy | Size   | Size ‚Üì |
|------------------|----------|--------|--------|
| Full PyTorch     | 99.3%    | 1650KB | ‚Äî      |
| Quantized (Torch)| 99.3%    | 472KB  | ‚Üì71%   |
| Quantized (ONNX) | 99.3%    | 472KB  | ‚Üì71%   |

---

## üì¶ Why This Matters for Fast AI

This work mimics real-world constraints in DoD/edge AI deployments:

- **Training ‚Üí Portability ‚Üí Inference**
- Compressing models without accuracy loss
- Deploying to environments where **Python is not available**
- Demonstrating **ONNX mastery** ‚Äî a key Fast AI track objective

---

## üöÄ Next Steps

- Benchmark CPU vs quantized ONNX inference latency
- Explore TensorRT and OpenVINO backends
- Package for deployment (e.g., REST API or embedded device)
- Extend to multi-digit MNIST or CIFAR10

---

üõ†Ô∏è *Built and maintained by Armand Debray*  

